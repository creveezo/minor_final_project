В этом репозитории доступен код моего проекта для предмета Технологии программирования. 

Проект представляет собой сервис для определения языка, на котором написан текст, введеный пользователем. В аналитической части рассматривается наиболее оптимальный размер корпуса, на котором расчитываются частотности, а также размер н-грамм, оптимально сочетающий точность и скорость определения.


Ход работы:
1. Собрать корпуса, на основе которых будет проанализирована частотность н-грамм. Для этого были взяты тексты библии, переведенные на языки мира. Тексты взяты из https://github.com/cisnlp/Taxi1500/tree/main/Taxi1500-c_v1.0
Анализировались следующие языки: croatian, czech, dutch, english, finnish, french, gaelic, german, indonesian, italian, magyar, polish, portugese, romanian, serbian, spanish, swahili, swedish.

2. Предобработка текстов. Тексты были очищены от знаков препинания, приведены к нижнему регистру.

3. Вычисление частотностей н-грамм. Были сформированы словари частотности разного размера.

4. Написана программа, принимающая на вход пользовательский текст. На выходе получаем топ-3 наиболее вероятных языков, на которых написан текст.

5. Анализ. Проанализированы оптимальный размер корпуса и оптимальные н-граммы, необходимые для определения языка.


Содержание репозитория:

Файл preprocesing.py - код, с помощью которого проводилась предобработка корпусов.

Папка corpora_preprocessed - папка с файлами, где каждый файл - предобработанный текст библии на данном языке.

diff_corpora_creating.py - код, с помощью которого создавались словари частотностей н-грамм разного размера. 

Папка dicts содержит словари, созданные с помощью diff_corpora_creating.py. В папке нет словарей размером 500k, 1M, full_text ввиду ограничения гитхаба на размер файлов.

for_analys.py - пробный код, на основе которого были выбраны наиболее подходящие параметры для работы.

langdetect_final.py - финальный вариант программы. 


